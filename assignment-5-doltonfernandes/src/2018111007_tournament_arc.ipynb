{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2018111007_tournament_arc.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA9pjDcjpg0A"
      },
      "source": [
        "# **Computer Vision Assignment 5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klt9b2wQpbI4"
      },
      "source": [
        "! pip install aicrowd-cli"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8WbSxS5tJF1",
        "outputId": "c5e51f3e-ec22-46be-b941-8feb3f67373f"
      },
      "source": [
        "API_KEY = \"375767f7b488df578d5c7e7ef9545f2d\" #Please enter your API Key from [https://www.aicrowd.com/participants/me]\n",
        "! aicrowd login --api-key $API_KEY"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mAPI Key valid\u001b[0m\n",
            "\u001b[32mSaved API Key successfully!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbK9jfV4tKDk",
        "outputId": "0247d643-4279-4b82-f71c-c0b0e3341aa3"
      },
      "source": [
        "! aicrowd dataset download --challenge chunin-exams-food-track-cv-2021"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_images.zip: 100% 754M/754M [00:19<00:00, 39.5MB/s]\n",
            "test_images.zip: 100% 33.9M/33.9M [00:01<00:00, 27.2MB/s]\n",
            "train.csv: 100% 253k/253k [00:00<00:00, 1.03MB/s]\n",
            "test.csv: 100% 7.27k/7.27k [00:00<00:00, 917kB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU3AtK8ktOIp",
        "outputId": "a1808546-3fb4-48a0-81dc-04f030a52f98"
      },
      "source": [
        "! wget https://gitlab.aicrowd.com/aicrowd/practice-challenges/aicrowd_FOODC_challenge/-/raw/master/dataset_info.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-18 11:19:51--  https://gitlab.aicrowd.com/aicrowd/practice-challenges/aicrowd_FOODC_challenge/-/raw/master/dataset_info.txt\n",
            "Resolving gitlab.aicrowd.com (gitlab.aicrowd.com)... 18.194.250.154, 18.195.114.113\n",
            "Connecting to gitlab.aicrowd.com (gitlab.aicrowd.com)|18.194.250.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3451 (3.4K) [text/plain]\n",
            "Saving to: ‘dataset_info.txt’\n",
            "\n",
            "dataset_info.txt    100%[===================>]   3.37K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-18 11:19:52 (526 MB/s) - ‘dataset_info.txt’ saved [3451/3451]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OywDsVjYt7kx"
      },
      "source": [
        "# library imports\n",
        "import os\n",
        "import tqdm\n",
        "import random\n",
        "import time\n",
        "import shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGtTpzg_lOls"
      },
      "source": [
        "! rm -r data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDL77RKltPOq"
      },
      "source": [
        "! unzip train_images.zip\n",
        "! unzip test_images.zip\n",
        "\n",
        "! mkdir data\n",
        "! mkdir data/train\n",
        "! mkdir data/val"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYIff7N3tzIk",
        "outputId": "6414860d-38c7-474c-de43-e9bbe0d5f60b"
      },
      "source": [
        "! ls -1 test_images | wc -l\n",
        "! cat test.csv | wc -l\n",
        "\n",
        "! ls -1 train_images | wc -l\n",
        "! cat train.csv | wc -l"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "484\n",
            "485\n",
            "9323\n",
            "9324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHgXbdIXyF1s"
      },
      "source": [
        "Creating label array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktpMK-D0t3HN",
        "outputId": "efc61304-7e6b-4959-8f0d-5b47a741fc72"
      },
      "source": [
        "with open('dataset_info.txt', 'r') as f:\n",
        "  labels = f.read()\n",
        "\n",
        "labels = labels.split('\\n')[1:]\n",
        "labels = [ i.strip().split('. ')[-1] for i in labels ]\n",
        "labels[:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BG', 'water', 'pizza-margherita-baked', 'broccoli', 'salad-leaf-salad-green']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I76C1EDeyJL9"
      },
      "source": [
        "Making label -> index and index -> label mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hiy1d9zFvXDP"
      },
      "source": [
        "lbl2idx = {}\n",
        "for i in range(len(labels)):\n",
        "  lbl2idx[labels[i]] = i\n",
        "\n",
        "idx2lbl = {}\n",
        "for i in range(len(labels)):\n",
        "  idx2lbl[i] = labels[i]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zasxQ63Mt4eH"
      },
      "source": [
        "for i in labels:\n",
        "  os.mkdir('data/train/' + i)\n",
        "  os.mkdir('data/val/' + i)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKfwqTrryPsc"
      },
      "source": [
        "Splitting data into train and val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is_j6oqmuOMo"
      },
      "source": [
        "classwise_alltrain_images = {}\n",
        "classwise_train_images = {}\n",
        "classwise_val_images = {}\n",
        "\n",
        "with open('train.csv', 'r') as f:\n",
        "  trainData = f.read()\n",
        "\n",
        "trainData = trainData.split('\\n')[1:-1]\n",
        "trainData = [ i.split(',') for i in trainData ]\n",
        "for i in trainData:\n",
        "  try:\n",
        "    classwise_alltrain_images[i[1]]\n",
        "    classwise_alltrain_images[i[1]].append(i[0])\n",
        "  except:\n",
        "    classwise_alltrain_images[i[1]] = []"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvt0n8JYa5fA"
      },
      "source": [
        "for i in classwise_alltrain_images.keys():\n",
        "  sizee = int(len(classwise_alltrain_images[i]) * 0.7)\n",
        "  for j in range(sizee):\n",
        "    classwise_alltrain_images[i].pop()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8Pi0sy_usaN"
      },
      "source": [
        "for i in classwise_alltrain_images.keys():\n",
        "  trainSamples = int(len(classwise_alltrain_images[i]) * 0.8)\n",
        "  trainSamples = random.sample(range(0, len(classwise_alltrain_images[i])), trainSamples)\n",
        "  testSamples = [ j for j in range(len(classwise_alltrain_images[i])) if j not in trainSamples ]\n",
        "  classwise_train_images[i] = [classwise_alltrain_images[i][j] for j in trainSamples]\n",
        "  classwise_val_images[i] = [classwise_alltrain_images[i][j] for j in testSamples]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld0PGIS_utq4"
      },
      "source": [
        "for i in classwise_train_images.keys():\n",
        "  for j in classwise_train_images[i]:\n",
        "    shutil.copyfile('train_images/' + j, 'data/train/' + i + '/' + j)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acvEODzSu1eL"
      },
      "source": [
        "for i in classwise_val_images.keys():\n",
        "  for j in classwise_val_images[i]:\n",
        "    shutil.copyfile('train_images/' + j, 'data/val/' + i + '/' + j)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCFZ2DwQySj1"
      },
      "source": [
        "Making list of all training and validation samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV-79Qweu9jS"
      },
      "source": [
        "train_images_list = []\n",
        "train_labels_list = []\n",
        "for i in classwise_train_images.keys():\n",
        "  for j in classwise_train_images[i]:\n",
        "    train_images_list.append('data/train/' + i + '/' + j)\n",
        "    train_labels_list.append(lbl2idx[i])\n",
        "\n",
        "val_images_list = []\n",
        "val_labels_list = []\n",
        "for i in classwise_val_images.keys():\n",
        "  for j in classwise_val_images[i]:\n",
        "    val_images_list.append('data/val/' + i + '/' + j)\n",
        "    val_labels_list.append(lbl2idx[i])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut4azkxJyU4E"
      },
      "source": [
        "Custom Food Dataset Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28n0C8iPv__y"
      },
      "source": [
        "class FoodData(Dataset):\n",
        "  def __init__(self, list_images, list_labels):\n",
        "    self.list_images = list_images\n",
        "    self.list_labels = list_labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.list_labels)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img = cv2.imread(self.list_images[index])\n",
        "    img = cv2.resize(img, (224, 224)).astype(np.float64) / 255\n",
        "    lbl = np.zeros(len(labels)).astype(np.float)\n",
        "    lbl[self.list_labels[index]] = 1\n",
        "    return {'feature': img, 'label': lbl}"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb61SxQ4yeKb"
      },
      "source": [
        "Creating Dataset object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHr-GT-jxSyR"
      },
      "source": [
        "train_dl = FoodData(train_images_list, train_labels_list)\n",
        "val_dl = FoodData(val_images_list, val_labels_list)"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbaHTrVyYdFy",
        "outputId": "44a67322-13e1-4241-8b8a-9f922c65a10a"
      },
      "source": [
        "train_dl.__getitem__(0)['feature'].shape"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65536,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgl9_wt-zIBB"
      },
      "source": [
        "Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgDCKNiUxlYa"
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(train_dl, shuffle = False, batch_size = 128, num_workers = 2)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dl, shuffle = True, batch_size = 128, num_workers = 2)"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq1GaP9n1L4s"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA1yvgec08jK"
      },
      "source": [
        "class FoodClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FoodClassifier, self).__init__()\n",
        "    self.layer1 = models.densenet161(pretrained=True)\n",
        "    self.layer1.fc = nn.Sequential(\n",
        "                  nn.Linear(1024, 256, bias=True), \n",
        "                  nn.ReLU(), \n",
        "                  nn.Dropout(0.4),\n",
        "                  nn.Linear(256, len(labels)),                   \n",
        "                  nn.LogSoftmax(dim=1)\n",
        "              )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer1(x)"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2Vz6yYJ38Xy"
      },
      "source": [
        "Training code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbDQWIFjLOPm"
      },
      "source": [
        "def check_cuda():\n",
        "    _cuda = False\n",
        "    if torch.cuda.is_available():\n",
        "        _cuda = True\n",
        "    return _cuda"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQXL8xQdI9dO"
      },
      "source": [
        "def train_model(model, train_loader, val_loader):\n",
        "    n_epochs = 10\n",
        "    bestModel = model\n",
        "    bestLoss = 1000000\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = 0.0\n",
        "        model.train()\n",
        "        for data_tmp in tqdm.tqdm(train_loader):\n",
        "            # move tensors to GPU\n",
        "            data, target = data_tmp['feature'].cuda().float(), data_tmp['label'].cuda().float()\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()*data.size(0)\n",
        "        # calculate average losses\n",
        "        train_loss = train_loss/len(train_loader.dataset)\n",
        "        # print training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
        "        lossVal = val_model(model, val_dataloader)\n",
        "        train_losses.append(train_loss)\n",
        "        if lossVal < bestLoss:\n",
        "          bestLoss = lossVal\n",
        "          bestModel = model\n",
        "    return model"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PabsxrWWizzY"
      },
      "source": [
        "def val_model(model, test_loader):\n",
        "    losss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    model.eval()\n",
        "    for data_tmp in tqdm.tqdm(test_loader):\n",
        "        # move tensors to GPU\n",
        "        data, target = data_tmp['feature'].cuda().float(), data_tmp['label'].cuda().float()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        losss += loss.item()*data.size(0)\n",
        "        _, pred = torch.max(output, 1)\n",
        "        _, gt = torch.max(target, 1)\n",
        "        correct += (pred == gt).sum().cpu().detach().numpy()\n",
        "        total += len(gt)\n",
        "    val_losses.append(losss)\n",
        "    print('\\nValidation loss =',losss)\n",
        "    print('Validation accuracy =', (correct / total) * 100, '%')\n",
        "    return losss"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HYP1q-2LD6o"
      },
      "source": [
        "train_model(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMCvfpowLJrH"
      },
      "source": [
        "val_model(model, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}